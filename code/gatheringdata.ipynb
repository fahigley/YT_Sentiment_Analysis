{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Project\n",
    "Youtube comment sentiment analysis\n",
    "\n",
    "Questions:\n",
    "1. In general, do YouTube comments lean towards a more positive or negative sentiment?\n",
    "2. Which genre of YouTube videos tends to attract the most positive feedback in the comments section?\n",
    "3. What is the sentiment towards controversial topics on YouTube?\n",
    "\n",
    "Approach:\n",
    "1. Gather data using Youtube api and make out into csv or other dataset file(columns are going to be g index, title, genre, controvertial(flag), the comment its self)\n",
    "2. Create ai sentiment alaysis model\n",
    "3. Train model\n",
    "4. Use model to answer questions\n",
    "\n",
    "Other:\n",
    "1. Youtube comments will only be the main comments no replies to comments\n",
    "2. Comments will be limited to less than 50,000 per video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import csv\n",
    "import pandas as pd\n",
    "import langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gathering comments\n",
    "def get_youtube_comments(video_id, max_results=100, max_comments=50000):\n",
    "    video_comments = []\n",
    "    comment_count = 0\n",
    "    youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "\n",
    "    # try a request\n",
    "    try:\n",
    "        video_response = youtube.commentThreads().list(part=\"snippet\", videoId=video_id, maxResults=max_results).execute()\n",
    "    except Exception as e:\n",
    "        return video_comments\n",
    "\n",
    "    # get comments\n",
    "    while video_response:\n",
    "        for item in video_response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            video_comments.append(comment)\n",
    "            comment_count += 1\n",
    "\n",
    "            # check if the max comments gotten\n",
    "            if comment_count >= max_comments:\n",
    "                return video_comments\n",
    "\n",
    "        # check for more pages\n",
    "        nextPageToken = video_response.get('nextPageToken')\n",
    "        if nextPageToken:\n",
    "            try:\n",
    "                video_response = youtube.commentThreads().list(part=\"snippet\", videoId=video_id, maxResults=max_results, pageToken=nextPageToken).execute()\n",
    "            except Exception as e:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    return video_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_CSV(name, comments):\n",
    "    try:\n",
    "        #open file or create new on \n",
    "        with open(name, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "\n",
    "            #if no header, make header\n",
    "            if file.tell() == 0:\n",
    "                writer.writerow(['Index', 'Comments'])\n",
    "\n",
    "            #write comments to csv\n",
    "            for index, value in enumerate(comments):\n",
    "                writer.writerow([index, value])\n",
    "\n",
    "        print(f\"Data successfully written to {name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to CSV file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_csv(input_file, output_file):\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    #check if comment english\n",
    "    def is_english(comment):\n",
    "        try:\n",
    "            lang, confidence = langid.classify(comment)\n",
    "            return lang == 'en' and confidence > 0.5\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    #check comments\n",
    "    df['IsEnglish'] = df['Comments'].apply(is_english)\n",
    "    df = df[df['IsEnglish'] & df['Index'].notnull()]\n",
    "\n",
    "    #save engish comment\n",
    "    df[['Index', 'Comments']].to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get top 5 videos by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_gaming = ['hI1MMVt7xEo', 'urHuO7Zbhhw', 'fPPGz5Qxw8A', 'BJPc49z57bU']\n",
    "top_5_vlogs = ['HhM0BYCHL00', 'briN_W5yzYY','zU95-wX0xJo', '84WIaK3bl_s', 'WxfZkMm3wcg']\n",
    "top_5_music = ['JGwWNGJdvx8', 'RgKAFK5djSk', 'OPf0YbXqDm0', '9bZkp7q19f0', '09R8_2nJtjg']\n",
    "top_5_beauty = ['ex33wtqnNz8', 'OO3NO29L50U', 'mGs4CjeJiJQ', 'VD47yv2NfMw', 'Fz-DTp2iewQ']\n",
    "top_5_reaction = ['-XKdCBZEWeU', 'KFChuq6piZ8', 'dYh6R4Jhxoo', 'KyNJD8Ewcjk', 'm5m8NoPRkRw']\n",
    "top_controversial = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for videoid in top_gaming:\n",
    "    comments = get_youtube_comments(videoid)\n",
    "    to_CSV('data/RawCSV/gaming_comments.csv',comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for videoid in top_5_vlogs:\n",
    "    comments = get_youtube_comments(videoid)\n",
    "    to_CSV('data/RawCSV/vlog_comments.csv',comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for videoid in top_5_music:\n",
    "    comments = get_youtube_comments(videoid)\n",
    "    to_CSV('data/RawCSV/music_comments.csv',comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for videoid in top_5_beauty:\n",
    "    comments = get_youtube_comments(videoid)\n",
    "    to_CSV('data/RawCSV/beauty_comments.csv',comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for videoid in top_5_reaction:\n",
    "    comments = get_youtube_comments(videoid)\n",
    "    to_CSV('data/RawCSV/reaction_comments.csv',comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_csv('data/RawCSV/gaming_comments.csv', 'data/CleanCSV/gaming_comments_clean.csv')\n",
    "clean_csv('data/RawCSV/vlog_comments.csv', 'data/CleanCSV/vlog_comments_clean.csv')\n",
    "clean_csv('data/RawCSV/music_comments.csv', 'data/CleanCSV/music_comments_clean.csv')\n",
    "clean_csv('data/RawCSV/beauty_comments.csv', 'data/CleanCSV/beauty_comments_clean.csv')\n",
    "clean_csv('data/RawCSV/reaction_comments.csv', 'data/CleanCSV/reaction_comments_clean.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
